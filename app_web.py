"""
è¯­éŸ³å¯¹è¯ç³»ç»Ÿ Web åº”ç”¨
ä½¿ç”¨ Gradio æ„å»ºäº¤äº’ç•Œé¢ï¼Œæ”¯æŒéŸ³é¢‘è¾“å…¥è®¾å¤‡é€‰æ‹©ã€æ¨¡å‹é€‰æ‹©ã€å®æ—¶å¯¹è¯å’ŒéŸ³é¢‘æ’­æ”¾
"""

from typing import Optional
import gradio as gr
import os
import time
import requests
import threading
import queue
import numpy as np
from pathlib import Path
from src.asr.realtime_asr import RealtimeASR
from src.dialogue.router import DialogueRouter
from src.dialogue.general_agent import GeneralAgent
from src.dialogue.thu_agent import ThuAssistantAgent
from src.tts import GPTSoVITSTTS


class VoiceDialogueWebApp:
    """è¯­éŸ³å¯¹è¯ç³»ç»Ÿ Web åº”ç”¨ç±»"""
    def __init__(self):
        self.asr = None
        self.router = None
        self.tts = None
        self.tts_api_url = "http://127.0.0.1:8000"
        self.conversation_history = []
        
        # å®æ—¶æ¨¡å¼ç›¸å…³å˜é‡
        self.realtime_mode = False
        self.realtime_thread = None
        self.audio_queue = queue.Queue()
        self.speech_buffer = []
        self.silence_frames = 0
        self.is_speaking = False
        self.chunk_duration = 0.5  # éŸ³é¢‘å—æ—¶é•¿(ç§’)
        self.silence_threshold = 6  # é™éŸ³å¸§æ•°é˜ˆå€¼
        self.min_speech_frames = 4  # æœ€å°è¯­éŸ³å¸§æ•°
        
    def initialize_system(self, tts_api_url, gpt_model, sovits_model, ref_audio_path, ref_text):
        """
        åˆå§‹åŒ–è¯­éŸ³å¯¹è¯ç³»ç»Ÿ
        
        Args:
            tts_api_url: TTS API æœåŠ¡åœ°å€
            gpt_model: GPT æ¨¡å‹åç§°
            sovits_model: SoVITS æ¨¡å‹åç§°
            ref_audio_path: å‚è€ƒéŸ³é¢‘è·¯å¾„
            ref_text: å‚è€ƒæ–‡æœ¬
        """
        try:
            # åˆå§‹åŒ– ASRï¼ˆè¯­éŸ³è¯†åˆ«ï¼‰
            if self.asr is None:
                self.asr = RealtimeASR(model_name="large-v3", language="zh")
                print("âœ“ ASR æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–å¯¹è¯è·¯ç”±
            if self.router is None:
                # ä»ç¯å¢ƒå˜é‡è¯»å– API å¯†é’¥
                ark_api_key = os.getenv("ARK_API_KEY")
                if not ark_api_key:
                    raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ ARK_API_KEY")
                
                volc_ak = os.getenv("THU_AGENT_AK")
                volc_sk = os.getenv("THU_AGENT_SK")
                volc_account_id = os.getenv("THU_AGENT_ACCOUNT_ID")
                if not all([volc_ak, volc_sk, volc_account_id]):
                    raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ THU_AGENT_AK, THU_AGENT_SK, THU_AGENT_ACCOUNT_ID")
                
                # åˆ›å»º GeneralAgent
                general_agent = GeneralAgent(api_key=ark_api_key)
                
                # åˆ›å»º ThuAssistantAgent
                thu_agent = ThuAssistantAgent(
                    ak=volc_ak,
                    sk=volc_sk,
                    account_id=volc_account_id
                )
                
                # åˆ›å»º DialogueRouter
                self.router = DialogueRouter(
                    general_agent=general_agent,
                    thu_agent=thu_agent,
                    verbose=True
                )
                print("âœ“ å¯¹è¯è·¯ç”±åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ– TTSï¼ˆè¯­éŸ³åˆæˆï¼‰
            self.tts_api_url = tts_api_url
            self.tts = GPTSoVITSTTS(
                api_url=tts_api_url,
                gpt_model_name=gpt_model,
                sovits_model_name=sovits_model,
                ref_audio_path=ref_audio_path,
                ref_text=ref_text,
                ref_text_lang="ä¸­æ–‡"
            )
            print("âœ“ TTS æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–æˆåŠŸåè·å–è®¾å¤‡çŠ¶æ€ä¿¡æ¯ï¼ˆè®¾å¤‡ä¸‹æ‹‰ç”±åˆ·æ–°æŒ‰é’®å¡«å……ï¼‰
            _, device_status_msg = self.get_audio_devices()
            return "âœ“ ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼å¯ä»¥å¼€å§‹å¯¹è¯äº†ã€‚", device_status_msg
        
        except Exception as e:
            # åˆå§‹åŒ–å¤±è´¥æ—¶ä¹Ÿè¿”å›å¤±è´¥ä¿¡æ¯
            return f"âœ— åˆå§‹åŒ–å¤±è´¥: {str(e)}", str(e)
    
    def get_available_models(self, tts_api_url):
        """
        è·å–å¯ç”¨çš„ TTS æ¨¡å‹åˆ—è¡¨
        
        Args:
            tts_api_url: TTS API æœåŠ¡åœ°å€
        
        Returns:
            (gpt_models, sovits_models, status_message)
        """
        try:
            response = requests.get(f"{tts_api_url}/classic_model_list/v4", timeout=10)
            response.raise_for_status()
            models = response.json()
            
            gpt_models = models.get('gpt', [])
            sovits_models = models.get('sovits', [])
            
            if not gpt_models or not sovits_models:
                return [], [], "âš  æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹ï¼Œè¯·æ£€æŸ¥ TTS æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ"
            
            status = f"âœ“ æ‰¾åˆ° {len(gpt_models)} ä¸ª GPT æ¨¡å‹å’Œ {len(sovits_models)} ä¸ª SoVITS æ¨¡å‹"
            return gpt_models, sovits_models, status
        
        except requests.RequestException as e:
            return [], [], f"âœ— æ— æ³•è¿æ¥åˆ° TTS æœåŠ¡ ({tts_api_url}): {str(e)}"

    def get_audio_devices(self):
        """è·å–æœ¬åœ°å½•éŸ³è®¾å¤‡åˆ—è¡¨ï¼Œè¿”å› (choices, status_message)"""
        try:
            if self.asr is None:
                return [], "âœ— è¯·å…ˆåˆå§‹åŒ– ASR æ¨¡å— (ç‚¹å‡»åˆå§‹åŒ–ç³»ç»Ÿ)"
            devices = self.asr.list_audio_devices(show=False)
            choices = [f"{d['index']} - {d['name']}" for d in devices]
            status = f"âœ“ æ‰¾åˆ° {len(choices)} ä¸ªå½•éŸ³è¾“å…¥è®¾å¤‡"
            return choices, status
        except Exception as e:
            return [], f"âœ— è·å–è®¾å¤‡å¤±è´¥: {e}"
    
    def process_audio(self, audio_input):
        """
        å¤„ç†éŸ³é¢‘è¾“å…¥ï¼Œè¿”å›å¯¹è¯æ–‡æœ¬å’Œåˆæˆçš„è¯­éŸ³
        
        Args:
            audio_input: éŸ³é¢‘è¾“å…¥ï¼ˆæ–‡ä»¶è·¯å¾„æˆ– tupleï¼‰
        
        Returns:
            (user_text, bot_text, output_audio_path, conversation_log)
        """
        if not self.asr or not self.router or not self.tts:
            return "", "è¯·å…ˆåˆå§‹åŒ–ç³»ç»Ÿï¼", None, self._format_history()
        
        try:
            # å¤„ç†ä¸åŒçš„éŸ³é¢‘è¾“å…¥æ ¼å¼
            if isinstance(audio_input, tuple):
                # Gradio Audio ç»„ä»¶è¿”å› (sample_rate, audio_array)
                audio_path = "temp_input.wav"
                import soundfile as sf
                sf.write(audio_path, audio_input[1], audio_input[0])
            else:
                # ç›´æ¥æ˜¯æ–‡ä»¶è·¯å¾„
                audio_path = audio_input
            
            # æ­¥éª¤1ï¼šè¯­éŸ³è¯†åˆ«
            print(f"[ASR] æ­£åœ¨è¯†åˆ«éŸ³é¢‘: {audio_path}")
            user_text = self.asr.transcribe(audio_path)
            print(f"[ASR] è¯†åˆ«ç»“æœ: {user_text}")
            
            if not user_text or user_text.strip() == "":
                return "", "æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³ï¼Œè¯·é‡è¯•ã€‚", None, self._format_history()
            
            # æ­¥éª¤2ï¼šå¯¹è¯ç”Ÿæˆ
            print(f"[Dialogue] æ­£åœ¨ç”Ÿæˆå›å¤...")
            bot_text = self.router.route(
                user_query=user_text,
                post_process=True  # ç§»é™¤ Markdown æ ¼å¼
            )
            print(f"[Dialogue] å›å¤: {bot_text}")
            
            # æ­¥éª¤3ï¼šè¯­éŸ³åˆæˆ
            print(f"[TTS] æ­£åœ¨åˆæˆè¯­éŸ³...")
            timestamp = int(time.time())
            output_audio_path = f"outputs/response_{timestamp}.wav"
            os.makedirs("outputs", exist_ok=True)
            
            self.tts.synthesize(
                text=bot_text,
                output_path=output_audio_path,
                temperature=1.0,
                speed=1.0
            )
            print(f"[TTS] éŸ³é¢‘å·²ä¿å­˜: {output_audio_path}")
            
            # è®°å½•å¯¹è¯å†å²
            self.conversation_history.append({
                "user": user_text,
                "bot": bot_text,
                "timestamp": time.strftime("%H:%M:%S")
            })
            
            return user_text, bot_text, output_audio_path, self._format_history()
        
        except Exception as e:
            error_msg = f"å¤„ç†å¤±è´¥: {str(e)}"
            print(f"[ERROR] {error_msg}")
            return "", error_msg, None, self._format_history()
    
    def _format_history(self):
        """æ ¼å¼åŒ–å¯¹è¯å†å²ä¸ºæ˜¾ç¤ºæ–‡æœ¬"""
        if not self.conversation_history:
            return "æš‚æ— å¯¹è¯è®°å½•"
        
        history_text = ""
        for i, item in enumerate(self.conversation_history, 1):
            history_text += f"=== å¯¹è¯ {i} ({item['timestamp']}) ===\n"
            history_text += f"ğŸ‘¤ ç”¨æˆ·: {item['user']}\n"
            history_text += f"ğŸ¤– ç³»ç»Ÿ: {item['bot']}\n\n"
        
        return history_text
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []
        return "å¯¹è¯å†å²å·²æ¸…ç©º", self._format_history()
    
    def start_realtime_mode(self):
        """å¯åŠ¨å®æ—¶è¯­éŸ³å¯¹è¯æ¨¡å¼"""
        if not self.asr or not self.router or not self.tts:
            return "âŒ è¯·å…ˆåˆå§‹åŒ–ç³»ç»Ÿï¼", self._format_history(), None
        
        if self.realtime_mode:
            return "âš ï¸ å®æ—¶æ¨¡å¼å·²ç»åœ¨è¿è¡Œä¸­", self._format_history(), None
        
        self.realtime_mode = True
        self.speech_buffer = []
        self.silence_frames = 0
        self.is_speaking = False
        
        # æ¸…ç©ºéŸ³é¢‘é˜Ÿåˆ—
        while not self.audio_queue.empty():
            try:
                self.audio_queue.get_nowait()
            except queue.Empty:
                break
        
        return "âœ… å®æ—¶æ¨¡å¼å·²å¯åŠ¨ï¼Œå¼€å§‹è¯´è¯å§ï¼", self._format_history(), None
    
    def stop_realtime_mode(self):
        """åœæ­¢å®æ—¶è¯­éŸ³å¯¹è¯æ¨¡å¼"""
        self.realtime_mode = False
        self.speech_buffer = []
        self.silence_frames = 0
        self.is_speaking = False
        
        # æ¸…ç©ºéŸ³é¢‘é˜Ÿåˆ—
        while not self.audio_queue.empty():
            try:
                self.audio_queue.get_nowait()
            except queue.Empty:
                break
        
        return "â¹ï¸ å®æ—¶æ¨¡å¼å·²åœæ­¢", self._format_history(), None
    
    def process_realtime_audio(self, audio_chunk):
        """
        å¤„ç†å®æ—¶éŸ³é¢‘æµ
        
        Args:
            audio_chunk: éŸ³é¢‘æ•°æ® (sample_rate, audio_array)
        
        Yields:
            (status_text, conversation_log, audio_output)
        """
        if not self.realtime_mode:
            yield "â¹ï¸ å®æ—¶æ¨¡å¼æœªå¯åŠ¨", self._format_history(), None
            return
        
        if audio_chunk is None:
            yield "âš ï¸ æœªæ”¶åˆ°éŸ³é¢‘æ•°æ®", self._format_history(), None
            return
        
        try:
            # è§£æéŸ³é¢‘æ•°æ®
            sample_rate, audio_data = audio_chunk
            
            # è½¬æ¢ä¸ºå•å£°é“ float32
            if len(audio_data.shape) > 1:
                audio_data = audio_data.mean(axis=1)
            audio_data = audio_data.astype(np.float32)
            
            # é‡é‡‡æ ·åˆ° 16kHzï¼ˆå¦‚æœéœ€è¦ï¼‰
            if sample_rate != 16000:
                import scipy.signal
                audio_data = scipy.signal.resample(
                    audio_data,
                    int(len(audio_data) * 16000 / sample_rate)
                )
                sample_rate = 16000
            
            # è®¡ç®—éŸ³é¢‘èƒ½é‡
            energy = np.sqrt(np.mean(audio_data ** 2))
            vad_threshold = self.asr.vad_threshold if hasattr(self.asr, 'vad_threshold') else 0.01
            
            if energy > vad_threshold:
                # æ£€æµ‹åˆ°è¯­éŸ³
                if not self.is_speaking:
                    self.is_speaking = True
                    yield "ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³...", self._format_history(), None
                
                self.speech_buffer.append(audio_data)
                self.silence_frames = 0
            else:
                # é™éŸ³
                if self.is_speaking:
                    self.silence_frames += 1
                    self.speech_buffer.append(audio_data)  # ä¿ç•™ä¸€äº›é™éŸ³
                    
                    if self.silence_frames >= self.silence_threshold:
                        # é™éŸ³æ—¶é—´è¶³å¤Ÿï¼Œè§¦å‘è¯†åˆ«å’Œå¯¹è¯
                        if len(self.speech_buffer) >= self.min_speech_frames:
                            yield "ğŸ”„ å¤„ç†ä¸­...", self._format_history(), None
                            
                            # åˆå¹¶éŸ³é¢‘æ•°æ®
                            audio = np.concatenate(self.speech_buffer)
                            
                            # ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                            import soundfile as sf
                            timestamp = int(time.time())
                            temp_audio_path = f"temp_realtime_{timestamp}.wav"
                            sf.write(temp_audio_path, audio, sample_rate)
                            
                            # å¤„ç†éŸ³é¢‘ï¼ˆè¯†åˆ« + å¯¹è¯ + åˆæˆï¼‰
                            user_text, bot_text, output_audio_path, conv_log = self.process_audio(temp_audio_path)
                            
                            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                            try:
                                os.remove(temp_audio_path)
                            except:
                                pass
                            
                            # è¿”å›ç»“æœ
                            if output_audio_path:
                                yield f"âœ… å®Œæˆ\nğŸ‘¤: {user_text}\nğŸ¤–: {bot_text}", conv_log, output_audio_path
                            else:
                                yield f"âš ï¸ {bot_text}", conv_log, None
                        else:
                            yield "âš ï¸ è¯­éŸ³å¤ªçŸ­ï¼Œå·²å¿½ç•¥", self._format_history(), None
                        
                        # é‡ç½®çŠ¶æ€
                        self.speech_buffer = []
                        self.is_speaking = False
                        self.silence_frames = 0
            
        except Exception as e:
            yield f"âŒ å¤„ç†é”™è¯¯: {str(e)}", self._format_history(), None
            # é‡ç½®çŠ¶æ€
            self.speech_buffer = []
            self.is_speaking = False
            self.silence_frames = 0




def create_interface():
    """åˆ›å»º Gradio ç•Œé¢"""
    
    app = VoiceDialogueWebApp()
    
    with gr.Blocks(title="è¯­éŸ³å¯¹è¯ç³»ç»Ÿ") as demo:
        gr.Markdown("""
        # ğŸ™ï¸ è¯­éŸ³å¯¹è¯ç³»ç»Ÿ
        
        ä¸€ä¸ªé›†æˆäº†è¯­éŸ³è¯†åˆ«ã€æ™ºèƒ½å¯¹è¯å’Œè¯­éŸ³åˆæˆçš„ç«¯åˆ°ç«¯ç³»ç»Ÿ
        """)
        
        with gr.Tab("âš™ï¸ ç³»ç»Ÿé…ç½®"):
            gr.Markdown("### 1. TTS æœåŠ¡é…ç½®")
            
            with gr.Row():
                tts_api_url_input = gr.Textbox(
                    label="TTS API åœ°å€",
                    value="http://127.0.0.1:8000",
                    placeholder="http://127.0.0.1:8000"
                )
                refresh_models_btn = gr.Button("ğŸ”„ åˆ·æ–°æ¨¡å‹åˆ—è¡¨", size="sm")
            
            model_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
            
            gr.Markdown("### 2. æ¨¡å‹é€‰æ‹©")
            
            with gr.Row():
                gpt_model_dropdown = gr.Dropdown(
                    label="GPT æ¨¡å‹",
                    choices=[],
                    interactive=True
                )
                sovits_model_dropdown = gr.Dropdown(
                    label="SoVITS æ¨¡å‹",
                    choices=[],
                    interactive=True
                )
            
            gr.Markdown("### 3. å‚è€ƒéŸ³é¢‘é…ç½®")
            
            ref_audio_path_input = gr.Textbox(
                label="å‚è€ƒéŸ³é¢‘è·¯å¾„ï¼ˆç›¸å¯¹æœåŠ¡ç«¯ï¼‰",
                value="./custom_refs/jianhua_tao.wav",
                placeholder="./custom_refs/your_ref_audio.wav"
            )
            
            ref_text_input = gr.Textbox(
                label="å‚è€ƒéŸ³é¢‘æ–‡æœ¬",
                value="è¿™ä¸ªç»„å§”ä¼šçš„é‚€è¯·å•Šï¼Œèƒ½æœ‰æœºä¼šç»™å¤§å®¶åšä¸€äº›å·¥ä½œä¸Šçš„ä¸€äº›åˆ†äº«",
                placeholder="å‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡æœ¬å†…å®¹",
                lines=2
            )
            
            init_btn = gr.Button("ğŸš€ åˆå§‹åŒ–ç³»ç»Ÿ", variant="primary", size="lg")
            init_status = gr.Textbox(label="åˆå§‹åŒ–çŠ¶æ€", interactive=False)
            device_status_sys = gr.Textbox(label="è®¾å¤‡çŠ¶æ€ï¼ˆç³»ç»Ÿï¼‰", interactive=False)
            
            # åˆ·æ–°æ¨¡å‹åˆ—è¡¨
            def update_models(api_url):
                gpt_models, sovits_models, status = app.get_available_models(api_url)
                return (
                    gr.Dropdown(choices=gpt_models, value=gpt_models[0] if gpt_models else None),
                    gr.Dropdown(choices=sovits_models, value=sovits_models[0] if sovits_models else None),
                    status
                )
            
            refresh_models_btn.click(
                fn=update_models,
                inputs=[tts_api_url_input],
                outputs=[gpt_model_dropdown, sovits_model_dropdown, model_status]
            )
            
            # åˆå§‹åŒ–ç³»ç»Ÿ
            init_btn.click(
                fn=app.initialize_system,
                inputs=[
                    tts_api_url_input,
                    gpt_model_dropdown,
                    sovits_model_dropdown,
                    ref_audio_path_input,
                    ref_text_input
                ],
                outputs=[init_status, device_status_sys]
            )
        
        with gr.Tab("ğŸ’¬ è¯­éŸ³å¯¹è¯"):
            gr.Markdown("### å¼€å§‹å¯¹è¯")
            gr.Markdown("ç‚¹å‡»éº¦å…‹é£å›¾æ ‡å½•éŸ³ï¼Œæˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
            with gr.Row():
                with gr.Column(scale=1):
                    audio_input = gr.Audio(
                        label="ğŸ¤ éŸ³é¢‘è¾“å…¥",
                        sources=["microphone", "upload"],
                        type="filepath"
                    )
                    process_btn = gr.Button("â–¶ï¸ å¤„ç†éŸ³é¢‘", variant="primary", size="lg")
                    gr.Markdown("### å¯¹è¯å†…å®¹")
                    user_text_output = gr.Textbox(
                        label="ğŸ‘¤ ç”¨æˆ·è¯´",
                        interactive=False,
                        lines=2
                    )
                    bot_text_output = gr.Textbox(
                        label="ğŸ¤– ç³»ç»Ÿå›å¤",
                        interactive=False,
                        lines=4
                    )
                    audio_output = gr.Audio(
                        label="ğŸ”Š åˆæˆè¯­éŸ³",
                        autoplay=True,
                        type="filepath"
                    )
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“ å¯¹è¯å†å²")
                    conversation_log = gr.Textbox(
                        label="",
                        interactive=False,
                        lines=20,
                        max_lines=30
                    )
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå†å²", size="sm")
            # å¤„ç†éŸ³é¢‘
            process_btn.click(
                fn=app.process_audio,
                inputs=[audio_input],
                outputs=[user_text_output, bot_text_output, audio_output, conversation_log]
            )
            # æ¸…ç©ºå†å²
            clear_btn.click(
                fn=app.clear_history,
                inputs=[],
                outputs=[bot_text_output, conversation_log]
            )
        
        with gr.Tab("ğŸ™ï¸ å®æ—¶å¯¹è¯"):
            gr.Markdown("### å®æ—¶è¯­éŸ³å¯¹è¯")
            gr.Markdown("å¯åŠ¨åæŒç»­å½•éŸ³ï¼Œæ£€æµ‹åˆ°è¯­éŸ³å¹¶è¯†åˆ«åˆ°é™éŸ³åè‡ªåŠ¨å¤„ç†å¹¶å›å¤")
            
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ¤ å®æ—¶éŸ³é¢‘æµ")
                    realtime_audio_input = gr.Audio(
                        label="",
                        sources=["microphone"],
                        streaming=True,
                        type="numpy"
                    )
                    
                    with gr.Row():
                        start_realtime_btn = gr.Button("ğŸŸ¢ å¯åŠ¨å®æ—¶æ¨¡å¼", variant="primary", size="lg")
                        stop_realtime_btn = gr.Button("ğŸ”´ åœæ­¢å®æ—¶æ¨¡å¼", variant="stop", size="lg")
                    
                    realtime_status = gr.Textbox(
                        label="ğŸ“Š çŠ¶æ€",
                        interactive=False,
                        lines=5
                    )
                    
                    realtime_audio_output = gr.Audio(
                        label="ğŸ”Š åˆæˆè¯­éŸ³",
                        autoplay=True,
                        type="filepath"
                    )
                
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“ å¯¹è¯å†å²")
                    realtime_conversation_log = gr.Textbox(
                        label="",
                        interactive=False,
                        lines=25,
                        max_lines=30
                    )
                    realtime_clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå†å²", size="sm")
            
            # å¯åŠ¨å®æ—¶æ¨¡å¼
            start_realtime_btn.click(
                fn=app.start_realtime_mode,
                inputs=[],
                outputs=[realtime_status, realtime_conversation_log, realtime_audio_output]
            )
            
            # åœæ­¢å®æ—¶æ¨¡å¼
            stop_realtime_btn.click(
                fn=app.stop_realtime_mode,
                inputs=[],
                outputs=[realtime_status, realtime_conversation_log, realtime_audio_output]
            )
            
            # å¤„ç†å®æ—¶éŸ³é¢‘æµ
            realtime_audio_input.stream(
                fn=app.process_realtime_audio,
                inputs=[realtime_audio_input],
                outputs=[realtime_status, realtime_conversation_log, realtime_audio_output]
            )
            
            # æ¸…ç©ºå†å²
            realtime_clear_btn.click(
                fn=app.clear_history,
                inputs=[],
                outputs=[realtime_status, realtime_conversation_log]
            )
        
        with gr.Tab("â„¹ï¸ ä½¿ç”¨è¯´æ˜"):
            gr.Markdown("""
            ## ğŸ“– ä½¿ç”¨æ­¥éª¤
            
            ### 1ï¸âƒ£ å¯åŠ¨ TTS æœåŠ¡
            
            åœ¨ä½¿ç”¨æœ¬ç³»ç»Ÿå‰ï¼Œéœ€è¦å…ˆå¯åŠ¨ GPT-SoVITS-V4-Inference æœåŠ¡ï¼š
            
            ```bash
            cd GPT-SoVITS-V4-Inference
            python api.py
            ```
            
            ### 2ï¸âƒ£ é…ç½®ç³»ç»Ÿ
            
            å‰å¾€ **"ç³»ç»Ÿé…ç½®"** æ ‡ç­¾é¡µï¼š
            
            1. ç‚¹å‡» **"åˆ·æ–°æ¨¡å‹åˆ—è¡¨"** è·å–å¯ç”¨æ¨¡å‹
            2. é€‰æ‹© **GPT æ¨¡å‹** å’Œ **SoVITS æ¨¡å‹**
            3. é…ç½® **å‚è€ƒéŸ³é¢‘è·¯å¾„** å’Œ **å‚è€ƒæ–‡æœ¬**
            4. ç‚¹å‡» **"åˆå§‹åŒ–ç³»ç»Ÿ"** å®Œæˆé…ç½®
            
            ### 3ï¸âƒ£ å¼€å§‹å¯¹è¯
            
            å‰å¾€ **"è¯­éŸ³å¯¹è¯"** æ ‡ç­¾é¡µï¼š
            
            1. **å½•éŸ³æ–¹å¼**ï¼šç‚¹å‡»éº¦å…‹é£å›¾æ ‡å¼€å§‹å½•éŸ³ï¼Œå†æ¬¡ç‚¹å‡»åœæ­¢
            2. **ä¸Šä¼ æ–¹å¼**ï¼šç‚¹å‡»ä¸Šä¼ æŒ‰é’®ï¼Œé€‰æ‹©æœ¬åœ°éŸ³é¢‘æ–‡ä»¶
            3. ç‚¹å‡» **"å¤„ç†éŸ³é¢‘"** æŒ‰é’®
            4. ç³»ç»Ÿå°†è‡ªåŠ¨ï¼š
               - è¯†åˆ«è¯­éŸ³å†…å®¹
               - ç”Ÿæˆæ™ºèƒ½å›å¤
               - åˆæˆè¯­éŸ³å¹¶æ’­æ”¾
            5. æŸ¥çœ‹å³ä¾§ **å¯¹è¯å†å²** äº†è§£å®Œæ•´å¯¹è¯è®°å½•
            
            ### 4ï¸âƒ£ åŠŸèƒ½è¯´æ˜
            
            - **è‡ªåŠ¨æ’­æ”¾**ï¼šåˆæˆçš„è¯­éŸ³ä¼šè‡ªåŠ¨æ’­æ”¾
            - **å¯¹è¯å†å²**ï¼šæ‰€æœ‰å¯¹è¯è®°å½•ä¼šä¿å­˜åœ¨å³ä¾§é¢æ¿
            - **æ¸…ç©ºå†å²**ï¼šç‚¹å‡» "æ¸…ç©ºå†å²" æŒ‰é’®æ¸…é™¤æ‰€æœ‰è®°å½•
            - **æ¨¡å‹åˆ‡æ¢**ï¼šå¯éšæ—¶åœ¨é…ç½®é¡µé¢åˆ‡æ¢æ¨¡å‹å¹¶é‡æ–°åˆå§‹åŒ–
            
            ### âš ï¸ æ³¨æ„äº‹é¡¹
            
            1. **é¦–æ¬¡ä½¿ç”¨**ï¼šè¯·ç¡®ä¿å·²æŒ‰ç…§ README.md å®Œæˆç¯å¢ƒéƒ¨ç½²
            2. **TTS æœåŠ¡**ï¼šå¿…é¡»å…ˆå¯åŠ¨ TTS æœåŠ¡ï¼Œå¦åˆ™æ— æ³•åˆæˆè¯­éŸ³
            3. **éŸ³é¢‘æ ¼å¼**ï¼šæ”¯æŒ WAVã€MP3 ç­‰å¸¸è§æ ¼å¼
            4. **ç½‘ç»œç¯å¢ƒ**ï¼šTTS æœåŠ¡éœ€è¦èƒ½å¤Ÿè®¿é—®æœ¬åœ° APIï¼ˆé»˜è®¤ http://127.0.0.1:8000ï¼‰
            
            ### ğŸ› ï¸ æ•…éšœæ’é™¤
            
            **é—®é¢˜ï¼šæ— æ³•è·å–æ¨¡å‹åˆ—è¡¨**
            - æ£€æŸ¥ TTS æœåŠ¡æ˜¯å¦å¯åŠ¨
            - ç¡®è®¤ API åœ°å€æ­£ç¡®
            - å°è¯•è®¿é—® http://127.0.0.1:8000/classic_model_list/v4
            
            **é—®é¢˜ï¼šè¯­éŸ³è¯†åˆ«å¤±è´¥**
            - ç¡®ä¿éŸ³é¢‘æ¸…æ™°ï¼Œæ— æ˜æ˜¾å™ªéŸ³
            - å½•éŸ³æ—¶é•¿å»ºè®® 2-10 ç§’
            - æ£€æŸ¥éº¦å…‹é£æƒé™
            
            **é—®é¢˜ï¼šè¯­éŸ³åˆæˆå¤±è´¥**
            - æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½
            - ç¡®è®¤å‚è€ƒéŸ³é¢‘è·¯å¾„å­˜åœ¨
            - æŸ¥çœ‹ç»ˆç«¯æ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
            
            ## ğŸ™ï¸ å®æ—¶å¯¹è¯æ¨¡å¼ä½¿ç”¨è¯´æ˜
            
            ### ä»€ä¹ˆæ˜¯å®æ—¶å¯¹è¯æ¨¡å¼ï¼Ÿ
            
            å®æ—¶å¯¹è¯æ¨¡å¼å…è®¸ä½ åƒçœŸäººå¯¹è¯ä¸€æ ·ï¼Œæ— éœ€æ‰‹åŠ¨ç‚¹å‡»æŒ‰é’®ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹ä½ çš„è¯­éŸ³ã€è¯†åˆ«å†…å®¹ã€ç”Ÿæˆå›å¤å¹¶æ’­æ”¾ã€‚
            
            ### ä½¿ç”¨æ–¹æ³•
            
            1. å‰å¾€ **"å®æ—¶å¯¹è¯"** æ ‡ç­¾é¡µ
            2. ç‚¹å‡» **"å¯åŠ¨å®æ—¶æ¨¡å¼"** æŒ‰é’®
            3. å…è®¸æµè§ˆå™¨è®¿é—®éº¦å…‹é£æƒé™
            4. å¼€å§‹æ­£å¸¸è¯´è¯ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ï¼š
               - æ£€æµ‹åˆ°ä½ çš„è¯­éŸ³å¼€å§‹
               - ç­‰å¾…ä½ è¯´è¯ç»“æŸï¼ˆé™éŸ³çº¦ 3 ç§’ï¼‰
               - è‡ªåŠ¨è¯†åˆ«ã€ç”Ÿæˆå›å¤ã€æ’­æ”¾è¯­éŸ³
               - ç»§ç»­ç›‘å¬ä¸‹ä¸€è½®å¯¹è¯
            5. ç‚¹å‡» **"åœæ­¢å®æ—¶æ¨¡å¼"** ç»“æŸå¯¹è¯
            
            ### å·¥ä½œåŸç†
            
            - **VAD æ£€æµ‹**ï¼šä½¿ç”¨è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆVoice Activity Detectionï¼‰åˆ¤æ–­æ˜¯å¦åœ¨è¯´è¯
            - **è‡ªåŠ¨åˆ†æ®µ**ï¼šé™éŸ³è¶…è¿‡é˜ˆå€¼åè‡ªåŠ¨è§¦å‘å¤„ç†
            - **è¿ç»­å¯¹è¯**ï¼šå¤„ç†å®Œæˆåè‡ªåŠ¨ç»§ç»­ç›‘å¬ï¼Œæ— éœ€æ‰‹åŠ¨æ“ä½œ
            
            ### æ³¨æ„äº‹é¡¹
            
            - è¯´è¯æ—¶ä¿æŒç¯å¢ƒå®‰é™ï¼Œé¿å…èƒŒæ™¯å™ªéŸ³
            - æ¯å¥è¯ä¹‹é—´ç•™æœ‰æ˜æ˜¾åœé¡¿ï¼ˆçº¦ 3 ç§’ï¼‰
            - å¦‚æœè¯¯è§¦å‘ï¼Œå¯ä»¥ç‚¹å‡»åœæ­¢åé‡æ–°å¯åŠ¨
            - å®æ—¶æ¨¡å¼ä¸‹å¯¹è¯å†å²ä¼šè‡ªåŠ¨æ›´æ–°
            """)
    
    return demo


def main():
    """ä¸»å‡½æ•°ï¼šå¯åŠ¨ Web åº”ç”¨"""
    print("=" * 60)
    print("è¯­éŸ³å¯¹è¯ç³»ç»Ÿ Web åº”ç”¨")
    print("=" * 60)
    print("\nğŸ“‹ å¯åŠ¨å‰æ£€æŸ¥æ¸…å•ï¼š")
    print("  âœ“ ç¡®ä¿å·²å¯åŠ¨ GPT-SoVITS-V4-Inference æœåŠ¡")
    print("  âœ“ ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–åŒ…ï¼ˆpip install -r requirements.txtï¼‰")
    print("  âœ“ ç¡®ä¿å·²é…ç½®å¥½ API å¯†é’¥ï¼ˆç«å±±å¼•æ“ã€Deepseek ç­‰ï¼‰")
    print("\nğŸš€ æ­£åœ¨å¯åŠ¨ Web åº”ç”¨...\n")
    
    demo = create_interface()
    
    demo.launch(
        server_name="0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        server_port=7860,       # ç«¯å£å·
        share=False,            # ä¸åˆ›å»ºå…¬ç½‘é“¾æ¥ï¼ˆå¯æ”¹ä¸º Trueï¼‰
        show_error=True,        # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
        quiet=False,            # æ˜¾ç¤ºå¯åŠ¨æ—¥å¿—
        theme=gr.themes.Soft()
    )


if __name__ == "__main__":
    main()

"""
ä¸‹è½½ faster-whisper æ¨¡å‹
ä½¿ç”¨ HF_MIRROR åŠ é€Ÿä¸‹è½½
"""

import os
from pathlib import Path


def download_faster_whisper_models():
    """ä¸‹è½½ faster-whisper çš„ large ç³»åˆ—æ¨¡å‹"""
    
    # è®¾ç½® HF é•œåƒ
    os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
    
    try:
        from huggingface_hub import snapshot_download
    except ImportError:
        print("æ­£åœ¨å®‰è£… huggingface_hub...")
        os.system("pip install huggingface_hub")
        from huggingface_hub import snapshot_download
    
    # faster-whisper æ¨¡å‹åœ¨ HF ä¸Šçš„ä»“åº“ ID
    models = {
        "tiny": "Systran/faster-whisper-tiny",
        "base": "Systran/faster-whisper-base",
        "small": "Systran/faster-whisper-small",
        "medium": "Systran/faster-whisper-medium",
        "large-v1": "Systran/faster-whisper-large-v1",
        "large-v2": "Systran/faster-whisper-large-v2",
        "large-v3": "Systran/faster-whisper-large-v3",
    }
    
    print("=" * 80)
    print("ğŸ“¥ ä¸‹è½½ faster-whisper æ‰€æœ‰æ¨¡å‹")
    print("=" * 80)
    print(f"é•œåƒåœ°å€: {os.environ['HF_ENDPOINT']}")
    print(f"ç¼“å­˜ç›®å½•: ~/.cache/huggingface/hub/")
    print("=" * 80)
    print()
    
    for model_name, repo_id in models.items():
        print(f"\n{'='*80}")
        print(f"ğŸ“¦ ä¸‹è½½æ¨¡å‹: {model_name}")
        print(f"   ä»“åº“: {repo_id}")
        print(f"{'='*80}")
        
        try:
            # ä¸‹è½½æ¨¡å‹åˆ°ç¼“å­˜ç›®å½•
            local_path = snapshot_download(
                repo_id=repo_id,
                cache_dir=None,  # ä½¿ç”¨é»˜è®¤ç¼“å­˜ç›®å½•
                resume_download=True,  # æ”¯æŒæ–­ç‚¹ç»­ä¼ 
                local_files_only=False
            )
            
            print(f"âœ… {model_name} ä¸‹è½½å®Œæˆï¼")
            print(f"   æœ¬åœ°è·¯å¾„: {local_path}")
            
        except Exception as e:
            print(f"âŒ {model_name} ä¸‹è½½å¤±è´¥: {e}")
            continue
    
    print("\n" + "=" * 80)
    print("âœ… æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
    print("=" * 80)
    print("\nä½¿ç”¨æ–¹æ³•:")
    print("  from faster_whisper import WhisperModel")
    print("  model = WhisperModel('large-v3', device='cuda')")
    print()


if __name__ == "__main__":
    download_faster_whisper_models()

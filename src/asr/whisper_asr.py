"""
Whisper è¯­éŸ³è¯†åˆ«æ¨¡å—
åŸºäº OpenAI Whisper å®ç°è¯­éŸ³è½¬æ–‡å­—
"""

import whisper
import numpy as np
import torch
from pathlib import Path
from typing import Optional, Union, Dict, Any
import time


class WhisperASR:
    """Whisper è¯­éŸ³è¯†åˆ«ç±»"""
    
    # å¯ç”¨æ¨¡å‹åŠå…¶ç‰¹ç‚¹
    MODELS = {
        'tiny':     {'params': '39M',  'vram': '~1GB',  'speed': '~32x'},
        'base':     {'params': '74M',  'vram': '~1GB',  'speed': '~16x'},
        'small':    {'params': '244M', 'vram': '~2GB',  'speed': '~6x'},
        'medium':   {'params': '769M', 'vram': '~5GB',  'speed': '~2x'},
        'large':    {'params': '1550M','vram': '~10GB', 'speed': '~1x'},
        'large-v2': {'params': '1550M','vram': '~10GB', 'speed': '~1x'},
        'large-v3': {'params': '1550M','vram': '~10GB', 'speed': '~1x'},
    }
    
    def __init__(
        self,
        model_name: str = "base",
        device: Optional[str] = None,
        download_root: Optional[str] = None
    ):
        """
        åˆå§‹åŒ– Whisper ASR
        
        Args:
            model_name: æ¨¡å‹åç§° (tiny/base/small/medium/large/large-v2/large-v3)
            device: è¿è¡Œè®¾å¤‡ (cuda/cpu)ï¼ŒNoneåˆ™è‡ªåŠ¨é€‰æ‹©
            download_root: æ¨¡å‹ä¸‹è½½ç›®å½•
        """
        self.model_name = model_name
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        
        print(f"ğŸ”§ åˆå§‹åŒ– Whisper ASR...")
        print(f"   æ¨¡å‹: {model_name}")
        print(f"   è®¾å¤‡: {self.device}")
        
        if model_name in self.MODELS:
            info = self.MODELS[model_name]
            print(f"   å‚æ•°é‡: {info['params']}, æ˜¾å­˜éœ€æ±‚: {info['vram']}, ç›¸å¯¹é€Ÿåº¦: {info['speed']}")
        
        # åŠ è½½æ¨¡å‹
        start_time = time.time()
        self.model = whisper.load_model(
            model_name,
            device=self.device,
            download_root=download_root
        )
        load_time = time.time() - start_time
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼è€—æ—¶: {load_time:.2f}ç§’")
        
    @classmethod
    def list_models(cls) -> Dict[str, Dict]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        return cls.MODELS
    
    def transcribe(
        self,
        audio: Union[str, np.ndarray],
        language: Optional[str] = None,
        task: str = "transcribe",
        **kwargs
    ) -> Dict[str, Any]:
        """
        è¯­éŸ³è½¬æ–‡å­—
        
        Args:
            audio: éŸ³é¢‘æ–‡ä»¶è·¯å¾„æˆ–numpyæ•°ç»„
            language: è¯­è¨€ä»£ç  (zh/en/jaç­‰)ï¼ŒNoneåˆ™è‡ªåŠ¨æ£€æµ‹
            task: ä»»åŠ¡ç±»å‹ (transcribe=è½¬å½• / translate=ç¿»è¯‘æˆè‹±æ–‡)
            **kwargs: å…¶ä»–Whisperå‚æ•°
            
        Returns:
            è¯†åˆ«ç»“æœå­—å…¸ï¼ŒåŒ…å« text, segments, language ç­‰
        """
        print(f"ğŸ¯ å¼€å§‹è¯­éŸ³è¯†åˆ«...")
        start_time = time.time()
        
        # å¦‚æœæ˜¯numpyæ•°ç»„ï¼Œç¡®ä¿æ˜¯float32ç±»å‹
        if isinstance(audio, np.ndarray):
            audio = audio.astype(np.float32)
        
        # æ‰§è¡Œè¯†åˆ«
        result = self.model.transcribe(
            audio,
            language=language,
            task=task,
            **kwargs
        )
        
        elapsed_time = time.time() - start_time
        
        print(f"âœ… è¯†åˆ«å®Œæˆï¼")
        print(f"   æ£€æµ‹è¯­è¨€: {result['language']}")
        print(f"   è€—æ—¶: {elapsed_time:.2f}ç§’")
        print(f"   è¯†åˆ«ç»“æœ: {result['text']}")
        
        # æ·»åŠ é¢å¤–ä¿¡æ¯
        result['elapsed_time'] = elapsed_time
        result['model'] = self.model_name
        result['device'] = self.device
        
        return result
    
    def transcribe_with_timestamps(
        self,
        audio: Union[str, np.ndarray],
        language: Optional[str] = None,
        word_timestamps: bool = True,
        **kwargs
    ) -> Dict[str, Any]:
        """
        å¸¦æ—¶é—´æˆ³çš„è¯­éŸ³è¯†åˆ«
        
        Args:
            audio: éŸ³é¢‘æ–‡ä»¶è·¯å¾„æˆ–numpyæ•°ç»„
            language: è¯­è¨€ä»£ç 
            word_timestamps: æ˜¯å¦è¿”å›è¯çº§æ—¶é—´æˆ³
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            è¯†åˆ«ç»“æœï¼ŒåŒ…å«è¯¦ç»†æ—¶é—´æˆ³
        """
        return self.transcribe(
            audio,
            language=language,
            word_timestamps=word_timestamps,
            **kwargs
        )
    
    def detect_language(self, audio: Union[str, np.ndarray]) -> tuple:
        """
        æ£€æµ‹éŸ³é¢‘è¯­è¨€
        
        Args:
            audio: éŸ³é¢‘æ–‡ä»¶è·¯å¾„æˆ–numpyæ•°ç»„
            
        Returns:
            (è¯­è¨€ä»£ç , æ¦‚ç‡)
        """
        # åŠ è½½éŸ³é¢‘
        if isinstance(audio, str):
            audio_array = whisper.load_audio(audio)
        else:
            audio_array = audio.astype(np.float32)
        
        # åªå–å‰30ç§’ç”¨äºè¯­è¨€æ£€æµ‹
        audio_array = whisper.pad_or_trim(audio_array)
        
        # è®¡ç®—melé¢‘è°±
        mel = whisper.log_mel_spectrogram(audio_array).to(self.device)
        
        # æ£€æµ‹è¯­è¨€
        _, probs = self.model.detect_language(mel)
        detected_lang = max(probs, key=probs.get)
        
        print(f"ğŸŒ æ£€æµ‹åˆ°è¯­è¨€: {detected_lang} (ç½®ä¿¡åº¦: {probs[detected_lang]:.2%})")
        
        return detected_lang, probs[detected_lang]
    
    def get_device_info(self) -> Dict[str, Any]:
        """è·å–è®¾å¤‡ä¿¡æ¯"""
        info = {
            'device': self.device,
            'model': self.model_name,
        }
        
        if self.device == 'cuda':
            info['cuda_available'] = torch.cuda.is_available()
            info['cuda_device_name'] = torch.cuda.get_device_name(0)
            info['cuda_memory_total'] = f"{torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB"
        
        return info


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # åˆå§‹åŒ–ASR
    asr = WhisperASR(model_name="base")
    
    # æ‰“å°è®¾å¤‡ä¿¡æ¯
    print("\nè®¾å¤‡ä¿¡æ¯:")
    for k, v in asr.get_device_info().items():
        print(f"  {k}: {v}")
    
    # å¦‚æœæœ‰æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼Œè¿›è¡Œè¯†åˆ«æµ‹è¯•
    test_file = "test_recording.wav"
    if Path(test_file).exists():
        result = asr.transcribe(test_file, language="zh")
        print(f"\nè¯†åˆ«ç»“æœ: {result['text']}")

"""
ASR æ¨¡å‹è¯„ä¼°è„šæœ¬
åœ¨ AISHELL-1 æ•°æ®é›†ä¸Šè¯„ä¼° Whisper å„ç‰ˆæœ¬æ¨¡å‹çš„å‡†ç¡®ç‡

è¯„ä¼°æŒ‡æ ‡ï¼š
- CER (Character Error Rate): å­—ç¬¦é”™è¯¯ç‡ï¼Œä¸­æ–‡ASRçš„ä¸»è¦è¯„ä¼°æŒ‡æ ‡
- WER (Word Error Rate): è¯é”™è¯¯ç‡ï¼ˆå‚è€ƒï¼‰

æ•°æ®é›†ï¼šAISHELL-1
- å¼€æºä¸­æ–‡è¯­éŸ³æ•°æ®é›†
- 178å°æ—¶é«˜è´¨é‡å½•éŸ³
- 400+è¯´è¯äºº
- ä¸‹è½½åœ°å€: https://www.openslr.org/33/
"""

import os
import sys
import json
import time
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, field
from collections import defaultdict
import re

import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.asr.whisper_asr import WhisperASR


@dataclass
class EvaluationResult:
    """è¯„ä¼°ç»“æœ"""
    model_name: str
    total_samples: int = 0
    total_chars_ref: int = 0
    total_substitutions: int = 0
    total_deletions: int = 0
    total_insertions: int = 0
    total_time: float = 0.0
    cer: float = 0.0
    rtf: float = 0.0  # Real-Time Factor
    errors: List[dict] = field(default_factory=list)
    
    def calculate_cer(self):
        """è®¡ç®— CER"""
        if self.total_chars_ref > 0:
            self.cer = (self.total_substitutions + self.total_deletions + self.total_insertions) / self.total_chars_ref
        return self.cer


def normalize_text(text: str) -> str:
    """
    æ–‡æœ¬è§„èŒƒåŒ–å¤„ç†
    
    å¤„ç†æ­¥éª¤ï¼š
    1. è½¬ä¸ºå°å†™ï¼ˆè‹±æ–‡ï¼‰
    2. ç§»é™¤æ ‡ç‚¹ç¬¦å·
    3. ç§»é™¤å¤šä½™ç©ºæ ¼
    4. ç»Ÿä¸€å…¨è§’/åŠè§’å­—ç¬¦
    """
    if not text:
        return ""
    
    # å…¨è§’è½¬åŠè§’
    text = text.translate(str.maketrans(
        'ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½šï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼º',
        '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'
    ))
    
    # è½¬å°å†™
    text = text.lower()
    
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼ˆä¿ç•™ä¸­æ–‡å­—ç¬¦ã€è‹±æ–‡å­—æ¯ã€æ•°å­—ï¼‰
    text = re.sub(r'[^\u4e00-\u9fff\u3400-\u4dbfa-z0-9]', '', text)
    
    return text


def levenshtein_distance(ref: str, hyp: str) -> Tuple[int, int, int, int]:
    """
    è®¡ç®— Levenshtein ç¼–è¾‘è·ç¦»
    
    ä½¿ç”¨åŠ¨æ€è§„åˆ’è®¡ç®—å°† ref è½¬æ¢ä¸º hyp æ‰€éœ€çš„æœ€å°ç¼–è¾‘æ“ä½œæ•°
    
    Args:
        ref: å‚è€ƒæ–‡æœ¬ï¼ˆæ ‡å‡†ç­”æ¡ˆï¼‰
        hyp: å‡è®¾æ–‡æœ¬ï¼ˆæ¨¡å‹è¾“å‡ºï¼‰
        
    Returns:
        (ç¼–è¾‘è·ç¦», æ›¿æ¢æ•°, åˆ é™¤æ•°, æ’å…¥æ•°)
    """
    m, n = len(ref), len(hyp)
    
    # dp[i][j] = å°† ref[:i] è½¬æ¢ä¸º hyp[:j] çš„æœ€å°ç¼–è¾‘è·ç¦»
    dp = [[0] * (n + 1) for _ in range(m + 1)]
    
    # åˆå§‹åŒ–è¾¹ç•Œ
    for i in range(m + 1):
        dp[i][0] = i  # åˆ é™¤ i ä¸ªå­—ç¬¦
    for j in range(n + 1):
        dp[0][j] = j  # æ’å…¥ j ä¸ªå­—ç¬¦
    
    # åŠ¨æ€è§„åˆ’å¡«è¡¨
    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if ref[i-1] == hyp[j-1]:
                dp[i][j] = dp[i-1][j-1]
            else:
                dp[i][j] = min(
                    dp[i-1][j-1] + 1,  # æ›¿æ¢
                    dp[i-1][j] + 1,    # åˆ é™¤
                    dp[i][j-1] + 1     # æ’å…¥
                )
    
    # å›æº¯è®¡ç®—å„ç±»é”™è¯¯æ•°é‡
    substitutions = deletions = insertions = 0
    i, j = m, n
    
    while i > 0 or j > 0:
        if i > 0 and j > 0 and ref[i-1] == hyp[j-1]:
            i -= 1
            j -= 1
        elif i > 0 and j > 0 and dp[i][j] == dp[i-1][j-1] + 1:
            substitutions += 1
            i -= 1
            j -= 1
        elif i > 0 and dp[i][j] == dp[i-1][j] + 1:
            deletions += 1
            i -= 1
        else:
            insertions += 1
            j -= 1
    
    return dp[m][n], substitutions, deletions, insertions


def calculate_cer(reference: str, hypothesis: str) -> Tuple[float, int, int, int, int]:
    """
    è®¡ç®—å­—ç¬¦é”™è¯¯ç‡ (CER)
    
    CER = (S + D + I) / N
    å…¶ä¸­ï¼š
    - S: æ›¿æ¢é”™è¯¯æ•°
    - D: åˆ é™¤é”™è¯¯æ•°
    - I: æ’å…¥é”™è¯¯æ•°
    - N: å‚è€ƒæ–‡æœ¬å­—ç¬¦æ•°
    
    Args:
        reference: å‚è€ƒæ–‡æœ¬
        hypothesis: è¯†åˆ«ç»“æœ
        
    Returns:
        (CER, æ›¿æ¢æ•°, åˆ é™¤æ•°, æ’å…¥æ•°, å‚è€ƒå­—ç¬¦æ•°)
    """
    # æ–‡æœ¬è§„èŒƒåŒ–
    ref = normalize_text(reference)
    hyp = normalize_text(hypothesis)
    
    if len(ref) == 0:
        return 0.0 if len(hyp) == 0 else 1.0, 0, 0, len(hyp), 0
    
    distance, sub, dele, ins = levenshtein_distance(ref, hyp)
    cer = distance / len(ref)
    
    return cer, sub, dele, ins, len(ref)


class AISHELL1Dataset:
    """
    AISHELL-1 æ•°æ®é›†åŠ è½½å™¨
    
    æ•°æ®é›†ç»“æ„ï¼š
    data_aishell/
    â”œâ”€â”€ wav/
    â”‚   â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ dev/
    â”‚   â””â”€â”€ test/
    â””â”€â”€ transcript/
        â””â”€â”€ aishell_transcript_v0.8.txt
    """
    
    def __init__(self, data_dir: str, split: str = "test"):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            data_dir: æ•°æ®é›†æ ¹ç›®å½•
            split: æ•°æ®é›†åˆ’åˆ† (train/dev/test)
        """
        self.data_dir = Path(data_dir)
        self.split = split
        self.samples = []
        
        self._load_transcripts()
    
    def _load_transcripts(self):
        """åŠ è½½è½¬å½•æ–‡æœ¬"""
        # è½¬å½•æ–‡ä»¶è·¯å¾„
        transcript_file = self.data_dir / "transcript" / "aishell_transcript_v0.8.txt"
        
        if not transcript_file.exists():
            # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
            alt_paths = [
                self.data_dir / "aishell_transcript_v0.8.txt",
                self.data_dir / "transcript.txt",
            ]
            for alt in alt_paths:
                if alt.exists():
                    transcript_file = alt
                    break
        
        if not transcript_file.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°è½¬å½•æ–‡ä»¶: {transcript_file}")
        
        # è¯»å–è½¬å½•æ–‡æœ¬
        transcripts = {}
        with open(transcript_file, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split(maxsplit=1)
                if len(parts) == 2:
                    utt_id, text = parts
                    # ç§»é™¤æ–‡æœ¬ä¸­çš„ç©ºæ ¼ï¼ˆä¸­æ–‡æ–‡æœ¬ï¼‰
                    text = text.replace(' ', '')
                    transcripts[utt_id] = text
        
        # æŸ¥æ‰¾éŸ³é¢‘æ–‡ä»¶
        wav_dir = self.data_dir / "wav" / self.split
        if not wav_dir.exists():
            wav_dir = self.data_dir / self.split
        
        if not wav_dir.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°éŸ³é¢‘ç›®å½•: {wav_dir}")
        
        # éå†éŸ³é¢‘æ–‡ä»¶
        for wav_file in wav_dir.rglob("*.wav"):
            utt_id = wav_file.stem
            if utt_id in transcripts:
                self.samples.append({
                    'id': utt_id,
                    'audio_path': str(wav_file),
                    'text': transcripts[utt_id]
                })
        
        print(f"ğŸ“ åŠ è½½ AISHELL-1 {self.split} é›†: {len(self.samples)} æ¡æ ·æœ¬")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        return self.samples[idx]
    
    def get_subset(self, n: int, seed: int = 42) -> List[dict]:
        """
        è·å–æ•°æ®å­é›†ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
        
        Args:
            n: æ ·æœ¬æ•°é‡
            seed: éšæœºç§å­
            
        Returns:
            æ ·æœ¬åˆ—è¡¨
        """
        np.random.seed(seed)
        indices = np.random.choice(len(self.samples), min(n, len(self.samples)), replace=False)
        return [self.samples[i] for i in indices]


def evaluate_model(
    model_name: str,
    samples: List[dict],
    device: str = None,
    verbose: bool = True
) -> EvaluationResult:
    """
    è¯„ä¼°å•ä¸ªæ¨¡å‹
    
    Args:
        model_name: æ¨¡å‹åç§°
        samples: æµ‹è¯•æ ·æœ¬åˆ—è¡¨
        device: è¿è¡Œè®¾å¤‡
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
    Returns:
        è¯„ä¼°ç»“æœ
    """
    print(f"\n{'='*60}")
    print(f"ğŸ“Š è¯„ä¼°æ¨¡å‹: {model_name}")
    print(f"{'='*60}")
    
    # åˆå§‹åŒ–æ¨¡å‹
    try:
        asr = WhisperASR(model_name=model_name, device=device)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None
    
    result = EvaluationResult(model_name=model_name)
    total_audio_duration = 0.0
    
    for i, sample in enumerate(samples):
        if verbose and (i + 1) % 10 == 0:
            print(f"   è¿›åº¦: {i+1}/{len(samples)}")
        
        try:
            # è®¡ç®—éŸ³é¢‘æ—¶é•¿
            import soundfile as sf
            audio_data, sr = sf.read(sample['audio_path'])
            audio_duration = len(audio_data) / sr
            total_audio_duration += audio_duration
            
            # è¯­éŸ³è¯†åˆ«
            start_time = time.time()
            asr_result = asr.transcribe(
                sample['audio_path'],
                language="zh",
                verbose=False
            )
            elapsed = time.time() - start_time
            
            # è·å–è¯†åˆ«ç»“æœ
            hypothesis = asr_result.get('text', '')
            reference = sample['text']
            
            # è®¡ç®— CER
            cer, sub, dele, ins, ref_len = calculate_cer(reference, hypothesis)
            
            # ç´¯åŠ ç»Ÿè®¡
            result.total_samples += 1
            result.total_chars_ref += ref_len
            result.total_substitutions += sub
            result.total_deletions += dele
            result.total_insertions += ins
            result.total_time += elapsed
            
            # è®°å½•é”™è¯¯æ ·æœ¬ï¼ˆCER > 20%ï¼‰
            if cer > 0.2:
                result.errors.append({
                    'id': sample['id'],
                    'reference': reference,
                    'hypothesis': hypothesis,
                    'cer': cer
                })
                
        except Exception as e:
            print(f"   âš ï¸ å¤„ç†æ ·æœ¬ {sample['id']} å¤±è´¥: {e}")
            continue
    
    # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
    result.calculate_cer()
    
    # è®¡ç®—å®æ—¶å› å­ (RTF)
    if total_audio_duration > 0:
        result.rtf = result.total_time / total_audio_duration
    
    # æ‰“å°ç»“æœ
    print(f"\nğŸ“ˆ è¯„ä¼°ç»“æœ - {model_name}")
    print(f"   æ ·æœ¬æ•°: {result.total_samples}")
    print(f"   æ€»å­—ç¬¦æ•°: {result.total_chars_ref}")
    print(f"   æ›¿æ¢é”™è¯¯: {result.total_substitutions}")
    print(f"   åˆ é™¤é”™è¯¯: {result.total_deletions}")
    print(f"   æ’å…¥é”™è¯¯: {result.total_insertions}")
    print(f"   CER: {result.cer:.2%}")
    print(f"   æ€»è€—æ—¶: {result.total_time:.2f}s")
    print(f"   RTF: {result.rtf:.3f} (< 1.0 è¡¨ç¤ºå¿«äºå®æ—¶)")
    
    return result


def run_benchmark(
    data_dir: str,
    models: List[str] = None,
    num_samples: int = 100,
    device: str = None,
    output_file: str = None
) -> Dict[str, EvaluationResult]:
    """
    è¿è¡Œå®Œæ•´åŸºå‡†æµ‹è¯•
    
    Args:
        data_dir: AISHELL-1 æ•°æ®é›†ç›®å½•
        models: è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨
        num_samples: æµ‹è¯•æ ·æœ¬æ•°é‡
        device: è¿è¡Œè®¾å¤‡
        output_file: ç»“æœè¾“å‡ºæ–‡ä»¶
        
    Returns:
        å„æ¨¡å‹è¯„ä¼°ç»“æœ
    """
    if models is None:
        models = ['tiny', 'base', 'small', 'medium', 'large', 'large-v2', 'large-v3']
    
    print("=" * 60)
    print("ğŸš€ Whisper ASR åŸºå‡†æµ‹è¯•")
    print("=" * 60)
    print(f"æ•°æ®é›†: AISHELL-1")
    print(f"æµ‹è¯•æ¨¡å‹: {', '.join(models)}")
    print(f"æ ·æœ¬æ•°é‡: {num_samples}")
    print(f"è¿è¡Œè®¾å¤‡: {device or 'è‡ªåŠ¨é€‰æ‹©'}")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®é›†
    try:
        dataset = AISHELL1Dataset(data_dir, split="test")
        samples = dataset.get_subset(num_samples)
    except FileNotFoundError as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        print("\nè¯·ç¡®ä¿ AISHELL-1 æ•°æ®é›†å·²æ­£ç¡®ä¸‹è½½å¹¶è§£å‹")
        print("ä¸‹è½½åœ°å€: https://www.openslr.org/33/")
        return {}
    
    # è¯„ä¼°å„æ¨¡å‹
    results = {}
    for model_name in models:
        result = evaluate_model(model_name, samples, device=device)
        if result:
            results[model_name] = result
    
    # æ‰“å°æ±‡æ€»è¡¨æ ¼
    print("\n" + "=" * 80)
    print("ğŸ“Š è¯„ä¼°ç»“æœæ±‡æ€»")
    print("=" * 80)
    print(f"{'æ¨¡å‹':<12} {'CER':>10} {'æ›¿æ¢':>8} {'åˆ é™¤':>8} {'æ’å…¥':>8} {'RTF':>8} {'è€—æ—¶':>10}")
    print("-" * 80)
    
    for model_name, result in results.items():
        print(f"{model_name:<12} {result.cer:>9.2%} {result.total_substitutions:>8} "
              f"{result.total_deletions:>8} {result.total_insertions:>8} "
              f"{result.rtf:>8.3f} {result.total_time:>9.1f}s")
    
    print("=" * 80)
    
    # ä¿å­˜ç»“æœ
    if output_file:
        output_data = {
            'dataset': 'AISHELL-1',
            'num_samples': num_samples,
            'results': {
                name: {
                    'cer': res.cer,
                    'substitutions': res.total_substitutions,
                    'deletions': res.total_deletions,
                    'insertions': res.total_insertions,
                    'rtf': res.rtf,
                    'total_time': res.total_time
                }
                for name, res in results.items()
            }
        }
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {output_file}")
    
    return results


def main():
    parser = argparse.ArgumentParser(description='Whisper ASR è¯„ä¼°è„šæœ¬')
    parser.add_argument('--data_dir', type=str, required=True,
                        help='AISHELL-1 æ•°æ®é›†ç›®å½•')
    parser.add_argument('--models', type=str, nargs='+',
                        default=['tiny', 'base', 'small', 'medium', 'large', 'large-v2', 'large-v3'],
                        help='è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨')
    parser.add_argument('--num_samples', type=int, default=100,
                        help='æµ‹è¯•æ ·æœ¬æ•°é‡ (é»˜è®¤: 100)')
    parser.add_argument('--device', type=str, default=None,
                        help='è¿è¡Œè®¾å¤‡ (cuda/cpu)')
    parser.add_argument('--output', type=str, default='evaluation_results.json',
                        help='ç»“æœè¾“å‡ºæ–‡ä»¶')
    
    args = parser.parse_args()
    
    run_benchmark(
        data_dir=args.data_dir,
        models=args.models,
        num_samples=args.num_samples,
        device=args.device,
        output_file=args.output
    )


if __name__ == "__main__":
    main()
